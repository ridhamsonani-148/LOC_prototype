version: 0.2

phases:
  install:
    runtime-versions:
      nodejs: 20
      python: 3.11
    commands:
      - echo "Installing AWS CDK CLI..."
      - npm install -g aws-cdk@latest
      - cd backend
      - npm install

  pre_build:
    commands:
      - echo "Building TypeScript..."
      - npm run build
      - echo "Bootstrapping CDK..."
      - cdk bootstrap --require-approval never

  build:
    commands:
      - |
        if [ "$ACTION" = "destroy" ]; then
          echo "Destroying stack..."
          cdk destroy LOCstack --force \
            --context projectName="$PROJECT_NAME" \
            --context dataBucketName="$DATA_BUCKET_NAME" \
            --context bedrockModelId="$BEDROCK_MODEL_ID"
        else
          echo "========================================="
          echo "Deploying Chronicling America Pipeline"
          echo "========================================="
          
          echo "Deploying CDK stack (without KB)..."
          cdk deploy LOCstack --require-approval never \
            --context projectName="$PROJECT_NAME" \
            --context dataBucketName="$DATA_BUCKET_NAME" \
            --context bedrockModelId="$BEDROCK_MODEL_ID" \
            --outputs-file outputs.json
          
          echo "Extracting outputs..."
          DATA_BUCKET=$(cat outputs.json | jq -r '.LOCstack.DataBucketName // empty')
          KB_ROLE_ARN=$(cat outputs.json | jq -r '.LOCstack.KnowledgeBaseRoleArn // empty')
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          
          echo ""
          echo "========================================="
          echo "Creating Knowledge Base Resources"
          echo "========================================="
          
          # Step 1: Create Neptune Analytics Graph with Vector Search
          echo "Step 1: Creating Neptune Analytics graph (16 m-NCUs) with Vector Search..."
          GRAPH_ID=$(aws neptune-graph create-graph \
            --graph-name "${PROJECT_NAME}-graph" \
            --provisioned-memory 16 \
            --no-public-connectivity \
            --vector-search-configuration '{"dimension":1024}' \
            --tags Project="$PROJECT_NAME" \
            --region "$CDK_DEFAULT_REGION" \
            --query 'id' --output text)
          
          if [ -z "$GRAPH_ID" ] || [ "$GRAPH_ID" = "None" ]; then
            echo "‚úó Failed to create Neptune Analytics graph"
            echo "Check if Neptune Analytics is available in region: $CDK_DEFAULT_REGION"
            exit 1
          fi
          
          echo "‚úì Graph created: $GRAPH_ID"
          GRAPH_ARN="arn:aws:neptune-graph:${CDK_DEFAULT_REGION}:${AWS_ACCOUNT_ID}:graph/${GRAPH_ID}"
          
          # Step 2: Wait for graph to be available
          echo "Step 2: Waiting for graph to be available..."
          MAX_WAIT=600
          ELAPSED=0
          while [ $ELAPSED -lt $MAX_WAIT ]; do
            STATUS=$(aws neptune-graph get-graph \
              --graph-identifier "$GRAPH_ID" \
              --region "$CDK_DEFAULT_REGION" \
              --query 'status' --output text 2>/dev/null || echo "ERROR")
            
            echo "  Graph status: $STATUS (waited ${ELAPSED}s)"
            
            if [ "$STATUS" = "AVAILABLE" ]; then
              echo "‚úì Graph is available"
              break
            elif [ "$STATUS" = "FAILED" ] || [ "$STATUS" = "DELETING" ]; then
              echo "‚úó Graph creation failed with status: $STATUS"
              exit 1
            elif [ "$STATUS" = "ERROR" ] || [ -z "$STATUS" ]; then
              echo "‚úó Failed to get graph status"
              exit 1
            fi
            
            sleep 30
            ELAPSED=$((ELAPSED + 30))
          done
          
          if [ $ELAPSED -ge $MAX_WAIT ]; then
            echo "‚úó Timeout waiting for graph to be available"
            exit 1
          fi
          
          # Step 3: Create Knowledge Base
          echo "Step 3: Creating Bedrock Knowledge Base..."
          KB_ID=$(aws bedrock-agent create-knowledge-base \
            --name "${PROJECT_NAME}-knowledge-base" \
            --role-arn "$KB_ROLE_ARN" \
            --knowledge-base-configuration '{
              "type": "VECTOR",
              "vectorKnowledgeBaseConfiguration": {
                "embeddingModelArn": "arn:aws:bedrock:'"$CDK_DEFAULT_REGION"'::foundation-model/amazon.titan-embed-text-v2:0"
              }
            }' \
            --storage-configuration '{
              "type": "NEPTUNE_ANALYTICS",
              "neptuneAnalyticsConfiguration": {
                "graphArn": "'"$GRAPH_ARN"'",
                "fieldMapping": {
                  "metadataField": "metadata",
                  "textField": "text"
                }
              }
            }' \
            --region "$CDK_DEFAULT_REGION" \
            --query 'knowledgeBase.knowledgeBaseId' --output text)
          
          if [ -z "$KB_ID" ] || [ "$KB_ID" = "None" ]; then
            echo "‚úó Failed to create Knowledge Base"
            exit 1
          fi
          
          echo "‚úì Knowledge Base created: $KB_ID"
          
          # Step 4: Create Data Source with Context Enrichment
          echo "Step 4: Creating Data Source with Context Enrichment..."
          BUCKET_ARN="arn:aws:s3:::${DATA_BUCKET}"
          
          DS_ID=$(aws bedrock-agent create-data-source \
            --name "${PROJECT_NAME}-s3-datasource" \
            --description "S3 data source for GraphRAG" \
            --knowledge-base-id "$KB_ID" \
            --data-source-configuration '{
              "type": "S3",
              "s3Configuration": {
                "bucketArn": "'"$BUCKET_ARN"'",
                "inclusionPrefixes": ["extracted/"]
              }
            }' \
            --vector-ingestion-configuration '{
              "chunkingConfiguration": {
                "chunkingStrategy": "FIXED_SIZE",
                "fixedSizeChunkingConfiguration": {
                  "maxTokens": 1000,
                  "overlapPercentage": 20
                }
              },
              "contextEnrichmentConfiguration": {
                "type": "BEDROCK_FOUNDATION_MODEL",
                "bedrockFoundationModelConfiguration": {
                  "modelArn": "arn:aws:bedrock:'"$CDK_DEFAULT_REGION"'::foundation-model/anthropic.claude-3-haiku-20240307-v1:0",
                  "enrichmentStrategyConfiguration": {
                    "method": "CHUNK_ENTITY_EXTRACTION"
                  }
                }
              }
            }' \
            --region "$CDK_DEFAULT_REGION" \
            --query 'dataSource.dataSourceId' --output text)
          
          if [ -z "$DS_ID" ] || [ "$DS_ID" = "None" ]; then
            echo "‚úó Failed to create Data Source"
            exit 1
          fi
          
          echo "‚úì Data Source created: $DS_ID"
          
          # Step 5: Update Lambda environment variables
          echo "Step 5: Updating Lambda environment variables..."
          
          # Get current fargate-trigger Lambda config to preserve existing values
          FARGATE_ENV=$(aws lambda get-function-configuration \
            --function-name "${PROJECT_NAME}-fargate-trigger" \
            --region "$CDK_DEFAULT_REGION" \
            --query 'Environment.Variables' \
            --output json)
          
          ECS_CLUSTER=$(echo "$FARGATE_ENV" | jq -r '.ECS_CLUSTER_NAME')
          TASK_DEF=$(echo "$FARGATE_ENV" | jq -r '.TASK_DEFINITION_ARN')
          SUBNETS=$(echo "$FARGATE_ENV" | jq -r '.SUBNET_IDS')
          SG=$(echo "$FARGATE_ENV" | jq -r '.SECURITY_GROUP_ID')
          START_C=$(echo "$FARGATE_ENV" | jq -r '.START_CONGRESS')
          END_C=$(echo "$FARGATE_ENV" | jq -r '.END_CONGRESS')
          BILL_T=$(echo "$FARGATE_ENV" | jq -r '.BILL_TYPES')
          
          # Update fargate-trigger Lambda with KB IDs
          aws lambda update-function-configuration \
            --function-name "${PROJECT_NAME}-fargate-trigger" \
            --environment Variables="{ECS_CLUSTER_NAME=${ECS_CLUSTER},TASK_DEFINITION_ARN=${TASK_DEF},SUBNET_IDS=${SUBNETS},SECURITY_GROUP_ID=${SG},BUCKET_NAME=${DATA_BUCKET},START_CONGRESS=${START_C},END_CONGRESS=${END_C},BILL_TYPES=${BILL_T},KNOWLEDGE_BASE_ID=${KB_ID},DATA_SOURCE_ID=${DS_ID}}" \
            --region "$CDK_DEFAULT_REGION" >/dev/null
          
          # Update kb-sync-trigger Lambda
          aws lambda update-function-configuration \
            --function-name "${PROJECT_NAME}-kb-sync-trigger" \
            --environment Variables="{KNOWLEDGE_BASE_ID=${KB_ID},DATA_SOURCE_ID=${DS_ID}}" \
            --region "$CDK_DEFAULT_REGION" >/dev/null
          
          # Update chat-handler Lambda
          aws lambda update-function-configuration \
            --function-name "${PROJECT_NAME}-chat-handler" \
            --environment Variables="{KNOWLEDGE_BASE_ID=${KB_ID},MODEL_ID=${BEDROCK_MODEL_ID}}" \
            --region "$CDK_DEFAULT_REGION" >/dev/null
          
          echo "‚úì Lambda environment variables updated (fargate-trigger, kb-sync-trigger, chat-handler)"
          
          echo ""
          echo "========================================="
          echo "‚úì Deployment Complete!"
          echo "========================================="
          echo "Graph ID: $GRAPH_ID"
          echo "Knowledge Base ID: $KB_ID"
          echo "Data Source ID: $DS_ID"
          echo "Data Bucket: $DATA_BUCKET"
          echo "========================================="
          
          # Extract optional outputs (may not exist in all stacks)
          STATE_MACHINE_ARN=$(cat outputs.json | jq -r '.LOCstack.StateMachineArn // empty')
          API_URL=$(cat outputs.json | jq -r '.LOCstack.APIGatewayURL // empty')
          CHAT_ENDPOINT=$(cat outputs.json | jq -r '.LOCstack.ChatEndpoint // empty')
          
          if [ -z "$DATA_BUCKET" ]; then
            echo "‚ùå ERROR: Could not extract Data Bucket from CDK deployment"
            exit 1
          fi
          
          echo "‚úÖ Deployment successful!"
          echo ""
          echo "========================================="
          echo "Deployment Summary"
          echo "========================================="
          echo "Data Bucket: $DATA_BUCKET"
          echo "Graph ID: $GRAPH_ID"
          echo "Knowledge Base ID: $KB_ID"
          echo "Data Source ID: $DS_ID"
          
          if [ -n "$STATE_MACHINE_ARN" ]; then
            echo "State Machine ARN: $STATE_MACHINE_ARN"
          fi
          
          if [ -n "$API_URL" ]; then
            echo "API Gateway URL: $API_URL"
          fi
          
          if [ -n "$CHAT_ENDPOINT" ]; then
            echo "Chat Endpoint: $CHAT_ENDPOINT"
          fi
          echo ""
          echo "========================================="
          echo "Next Steps"
          echo "========================================="
          
          if [ -n "$STATE_MACHINE_ARN" ]; then
            echo "1. Start pipeline execution:"
            echo "   aws stepfunctions start-execution \\"
            echo "     --state-machine-arn $STATE_MACHINE_ARN \\"
            echo "     --input '{\"start_date\":\"1815-08-01\",\"end_date\":\"1815-08-31\",\"max_pages\":10}'"
            echo ""
          fi
          
          if [ -n "$CHAT_ENDPOINT" ]; then
            echo "2. Test chat API:"
            echo "   curl -X POST $CHAT_ENDPOINT \\"
            echo "     -H 'Content-Type: application/json' \\"
            echo "     -d '{\"question\":\"Who are the people mentioned?\"}'"
            echo ""
          fi
          
          echo "3. Upload documents to S3:"
          echo "   aws s3 cp document.txt s3://${DATA_BUCKET}/extracted/"
          echo ""
          echo "4. Trigger Knowledge Base sync:"
          echo "   aws bedrock-agent start-ingestion-job \\"
          echo "     --knowledge-base-id $KB_ID \\"
          echo "     --data-source-id $DS_ID \\"
          echo "     --region $CDK_DEFAULT_REGION"
          echo ""
          echo "5. Monitor resources:"
          echo "   - Knowledge Base: https://console.aws.amazon.com/bedrock/home?region=${CDK_DEFAULT_REGION}#/knowledge-bases"
          echo "   - Neptune Analytics: https://console.aws.amazon.com/neptune-analytics/home?region=${CDK_DEFAULT_REGION}"
          echo "   - S3 Bucket: https://s3.console.aws.amazon.com/s3/buckets/${DATA_BUCKET}"
          echo ""
        fi

  post_build:
    commands:
      - echo "========================================="
      - echo "Deployment Complete"
      - echo "========================================="
      - |
        if [ "$ACTION" = "deploy" ]; then
          echo "‚úÖ Pipeline deployed successfully"
          echo "üìä Check CloudWatch Logs for Lambda execution details"
          echo "üîç Query Neptune via the chat API endpoint"
        else
          echo "‚úÖ Stack destroyed successfully"
        fi

artifacts:
  files:
    - "**/*"
  base-directory: "backend/cdk.out"
